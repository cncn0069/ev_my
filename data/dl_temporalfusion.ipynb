{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8e92b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import (\n",
    "    TemporalFusionTransformer,\n",
    "    TimeSeriesDataSet,\n",
    "    GroupNormalizer,\n",
    "    MAE,\n",
    "    QuantileLoss\n",
    ")\n",
    "\n",
    "group_cols = [\"station_location\", \"evse_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7730f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv('data_full.csv')\n",
    "\n",
    "num_cols = data_full.select_dtypes(include=[\"number\"]).columns\n",
    "data_full[num_cols] = data_full[num_cols].fillna(0)\n",
    "# Ïπ¥ÌÖåÍ≥†Î¶¨ Ïª¨Îüº Î¨∏ÏûêÏó¥ Î≥ÄÌôò\n",
    "for col in [\"station_location\", \"evse_name\", \"evse_type\", \"supports_discharge\", \"month\", \"weekday\"]:\n",
    "    if col in data_full.columns:\n",
    "        data_full[col] = data_full[col].astype(str)\n",
    "\n",
    "datetime_cols = [\n",
    "    \"connection_start_time_ts\", \"last_charge_end_time_ts\", \"charging_end_time_ts\",\n",
    "    \"connection_end_time_ts\", \"expected_departure_time_ts\"\n",
    "]\n",
    "\n",
    "for col in datetime_cols:\n",
    "    if col in data_full.columns and data_full[col].dtype == 'object':\n",
    "        data_full[col] = pd.to_datetime(data_full[col])\n",
    "        data_full[col] = data_full[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "698b2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            min  max  count\n",
      "station_location evse_name                 \n",
      "CSCS2015         0            0  205    206\n"
     ]
    }
   ],
   "source": [
    "data_full = data_full.sort_values(group_cols + [\"time_idx\"])\n",
    "\n",
    "# Í∑∏Î£πÎ≥ÑÎ°ú time_idx Ïû¨ÏÑ§Ï†ï (Ïòà: Í∞Å Í∑∏Î£π ÏãúÍ≥ÑÏó¥ÏóêÏÑú 0Î∂ÄÌÑ∞ ÏãúÏûëÌïòÎäî Ï†ïÏàò Ïù∏Îç±Ïä§)\n",
    "def reset_time_idx(df):\n",
    "    df = df.sort_values(\"time_idx\").reset_index(drop=True)\n",
    "    df[\"time_idx\"] = range(len(df))\n",
    "    return df\n",
    "\n",
    "data_full = data_full.groupby(group_cols).apply(reset_time_idx).reset_index(drop=True)\n",
    "\n",
    "print(data_full.groupby(group_cols)[\"time_idx\"].agg([\"min\", \"max\", \"count\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffd740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 111    | train\n",
      "3  | prescalers                         | ModuleDict                      | 272    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 4.3 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 783    | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n",
      "20 | output_layer                       | Linear                          | 119    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "27.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.2 K    Total params\n",
      "0.109     Total estimated model params size (MB)\n",
      "464       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f983a7739c304264b5ff39d041995b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7da06ec8fd244a39e605fc91c2abed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2196f2b858944507b1130bb0b849c279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 13.910646438598633\n"
     ]
    }
   ],
   "source": [
    "# ÏµúÎåÄ Ïù∏Îç±Ïä§ Î∞è ÌïôÏäµ/Í≤ÄÏ¶ù Î∂ÑÌï† Í∏∞Ï§Ä\n",
    "max_prediction_length = 30 * 24 *2\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data_full[\"time_idx\"].max() - max_prediction_length\n",
    "training_data = data_full[data_full[\"time_idx\"] <= training_cutoff]\n",
    "validation_data = data_full[data_full[\"time_idx\"] > training_cutoff]\n",
    "# --------------------\n",
    "# TimeSeriesDataSet ÏÉùÏÑ±\n",
    "# --------------------\n",
    "training = TimeSeriesDataSet(\n",
    "    data_full[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"requested_kwh\",\n",
    "    group_ids=group_cols,\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"station_location\", \"evse_name\", \"evse_type\", \"supports_discharge\"],\n",
    "    static_reals=[\"usage_departure_range\", \"post_charge_departure_range\", \"cluster\"] if \"usage_departure_range\" in data_full.columns else [],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\"],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        col for col in [\n",
    "            \"connection_start_time_ts\",\"last_charge_end_time_ts\", \"charging_end_time_ts\", \"connection_end_time_ts\", \"expected_departure_time_ts\",\n",
    "            \"expected_departure_time_missing\", \"idle_time_ts\", \"expected_usage_duration_ts\", \"expected_usage_duration_missing\",\n",
    "            \"expected_time_diff_ts\", \"expected_time_diff_missing\", \"actual_usage_duration_ts\", \"actual_charging_duration_ts\",\n",
    "            \"actual_charging_duration_missing\", \"start_delay_duration_ts\", \"start_delay_duration_missing\",\n",
    "            \"post_charge_departure_delay_ts\", \"post_charge_departure_delay_missing\",\n",
    "            \"usage_departure_time_diff_ts\", \"usage_departure_time_diff_missing\",\n",
    "            \"delivered_kwh\", \"requested_kwh\", \"kwh_request_diff\", \"kwh_per_usage_time\"\n",
    "        ] if col in data_full.columns\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(groups=group_cols, transformation=\"softplus\"),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data_full, predict=True, stop_randomization=True)\n",
    "\n",
    "# --------------------\n",
    "# Dataloader ÏÑ§Ï†ï\n",
    "# --------------------\n",
    "batch_size = 512\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=4)\n",
    "\n",
    "# --------------------\n",
    "# Trainer & Î™®Îç∏ Ï†ïÏùò\n",
    "# --------------------\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=\"cuda\",\n",
    "    gradient_clip_val=0.1,\n",
    "    enable_model_summary=True,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# ÌïôÏäµ\n",
    "# --------------------\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "# --------------------\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cuda\"))\n",
    "print(\"MAE:\", MAE()(predictions.output, predictions.y).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34.9355, 37.9210, 35.8729, 40.0564, 34.3832, 34.4398, 39.4118, 36.7339,\n",
      "         25.6542, 37.7875, 36.5588, 36.3540, 38.3027, 37.4756, 40.3747, 32.6620,\n",
      "         36.2315, 37.2804, 22.2992, 39.5477]], device='cuda:0')\n",
      "(tensor([[18.5000, 22.2100, 19.8400, 34.0100, 43.8200, 15.5000, 27.9900, 34.2600,\n",
      "         25.9500, 40.6600, 20.3700, 26.1900, 12.6100, 22.2000, 10.8500, 11.8000,\n",
      "         15.8100, 17.9500, 12.2500, 28.5100]], device='cuda:0'), None)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(predictions.output)\n",
    "print(predictions.y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "largeGarbage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
