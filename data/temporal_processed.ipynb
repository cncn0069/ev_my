{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a7ba2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:/CODE/401_python/Ev_my/data/epoch=14-step=1275.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     TemporalFusionTransformer,\n\u001b[32m      9\u001b[39m     TimeSeriesDataSet,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     QuantileLoss\n\u001b[32m     13\u001b[39m )\n\u001b[32m     16\u001b[39m best_model_path = \u001b[33m\"\u001b[39m\u001b[33mepoch=14-step=1275.ckpt\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 실제 경로로 변경\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m best_tft = \u001b[43mTemporalFusionTransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m group_cols = [\u001b[33m\"\u001b[39m\u001b[33mstation_location\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mevse_name\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\utilities\\model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1611\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1529\u001b[39m     **kwargs: Any,\n\u001b[32m   1530\u001b[39m ) -> Self:\n\u001b[32m   1531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1532\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1533\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1609\u001b[39m \n\u001b[32m   1610\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1611\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\core\\saving.py:63\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m map_location = map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     checkpoint = \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[32m     66\u001b[39m checkpoint = _pl_migrate_checkpoint(\n\u001b[32m     67\u001b[39m     checkpoint, checkpoint_path=(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     68\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\fabric\\utilities\\cloud_io.py:60\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(path_or_url, map_location, weights_only)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.hub.load_state_dict_from_url(\n\u001b[32m     55\u001b[39m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[32m     56\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     57\u001b[39m         weights_only=weights_only,\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m fs = get_filesystem(path_or_url)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.load(\n\u001b[32m     62\u001b[39m         f,\n\u001b[32m     63\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     64\u001b[39m         weights_only=weights_only,\n\u001b[32m     65\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\fsspec\\spec.py:1310\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1309\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1319\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\fsspec\\implementations\\local.py:201\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\fsspec\\implementations\\local.py:365\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    364\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\fsspec\\implementations\\local.py:370\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    372\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:/CODE/401_python/Ev_my/data/epoch=14-step=1275.ckpt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import (\n",
    "    TemporalFusionTransformer,\n",
    "    TimeSeriesDataSet,\n",
    "    GroupNormalizer,\n",
    "    MAE,\n",
    "    QuantileLoss\n",
    ")\n",
    "\n",
    "\n",
    "best_model_path = \"epoch=14-step=1275.ckpt\"  # 실제 경로로 변경\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "group_cols = [\"station_location\", \"evse_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소 time_idx: 0\n",
      "최대 time_idx: 18294\n",
      "전체 기간(시간 단위): 9147.408333333333\n",
      "post_charge_departure_range NaN 개수: 18600238\n",
      "post_charge_departure_range 무한대 개수: 0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/50area_dummy_processed.csv', dtype={\"evse_name\": str, \"station_location\": str})\n",
    "\n",
    "# UNIX timestamp → datetime (초 단위)\n",
    "data[\"last_charge_end_time_ts\"] = pd.to_datetime(data[\"last_charge_end_time_ts\"], unit='s', errors='coerce')\n",
    "\n",
    "# 결측 및 이상치 제거\n",
    "data = data.dropna(subset=[\"last_charge_end_time_ts\", \"evse_name\", \"station_location\"])\n",
    "data = data[data[\"last_charge_end_time_ts\"] >= pd.Timestamp(\"2000-01-01\")]\n",
    "\n",
    "# 시간 인덱스 30분 단위 (초/1800)\n",
    "data[\"time_idx_raw\"] = ((data[\"connection_start_time_ts\"] - data[\"connection_start_time_ts\"].min()).dt.total_seconds() // 1800).astype(int)\n",
    "\n",
    "# 조합별 모든 time_idx 채우기 (Missing timestep 처리)\n",
    "group_cols = [\"station_location\", \"evse_name\"]\n",
    "unique_groups = data[group_cols].drop_duplicates()\n",
    "\n",
    "# time_idx 전체 범위\n",
    "all_time_idx = np.arange(data[\"time_idx_raw\"].min(), data[\"time_idx_raw\"].max() + 1)\n",
    "\n",
    "# 모든 group × 모든 time_idx 조합 생성\n",
    "full_index = pd.DataFrame(\n",
    "    [(loc, evse, t) for loc, evse in unique_groups.values for t in all_time_idx],\n",
    "    columns=group_cols + [\"time_idx_raw\"]\n",
    ")\n",
    "\n",
    "# 기존 데이터와 조인하여 결측 timestep 채우기\n",
    "data_full = pd.merge(full_index, data, on=group_cols + [\"time_idx_raw\"], how='left')\n",
    "\n",
    "# 연속 인덱스 재설정 (group 별 0부터 순차적)\n",
    "data_full = data_full.sort_values(group_cols + [\"time_idx_raw\"])\n",
    "data_full[\"time_idx\"] = data_full.groupby(group_cols).cumcount()\n",
    "\n",
    "\n",
    "data_full = fill_nearest_within_range(\n",
    "    data_full,\n",
    "    group_cols=['station_location', 'evse_name'],\n",
    "    target_col='last_charge_end_time_ts',\n",
    "    window=100\n",
    ")\n",
    "\n",
    "# charging_end_time_ts, connection_end_time_ts, expected_departure_time_ts, idle_time_ts : forward fill\n",
    "for col in [\"charging_end_time_ts\", \"connection_end_time_ts\", \"expected_departure_time_ts\", \"idle_time_ts\"]:\n",
    "    if col in data_full.columns:\n",
    "        data_full[col] = data_full.groupby(group_cols)[col].ffill()\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 타입 지정\n",
    "data_full[\"weekday\"] = data_full[\"connection_start_time_ts\"].dt.weekday.astype(str).astype(\"category\")\n",
    "data_full[\"month\"] = data_full[\"connection_start_time_ts\"].dt.month.astype(str).astype(\"category\")\n",
    "data_full[\"evse_type\"] = data_full[\"evse_type\"].astype(str).astype(\"category\")\n",
    "data_full[\"supports_discharge\"] = data_full[\"supports_discharge\"].astype(str).astype(\"category\")\n",
    "\n",
    "# 추가 feature\n",
    "data_full[\"log_volume\"] = np.log(data_full[\"requested_kwh\"].fillna(0) + 1e-8)\n",
    "data_full[\"avg_volume_by_evsename\"] = data_full.groupby(group_cols, observed=True)[\"requested_kwh\"].transform(\"mean\")\n",
    "\n",
    "missing_cols = [\n",
    "    \"actual_charging_duration_missing\", \"start_delay_duration_missing\", \"post_charge_departure_delay_missing\",\n",
    "    \"charging_end_time_ts\", \"last_charge_end_time_ts\", \"connection_end_time_ts\", \n",
    "    \"expected_departure_time_ts\", \"idle_time_ts\", \"expected_usage_duration_ts\", \n",
    "    \"expected_time_diff_ts\", \"actual_usage_duration_ts\", \"actual_charging_duration_ts\", \n",
    "    \"start_delay_duration_ts\", \"post_charge_departure_delay_ts\", \n",
    "    \"usage_departure_time_diff_ts\",\"expected_time_diff_missing\"\n",
    "]\n",
    "for col in missing_cols:\n",
    "    if col in data_full.columns:\n",
    "        data_full[col] = data_full[col].fillna(0)\n",
    "\n",
    "# 타겟 및 필수 필드 NaN 행 제거\n",
    "data_full = data_full.dropna(subset=[\"requested_kwh\", \"station_location\", \"evse_name\", \"time_idx\"])\n",
    "\n",
    "# 최대 인덱스 및 학습/검증 분할 기준\n",
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data_full[\"time_idx\"].max() - max_prediction_length\n",
    "# --------------------\n",
    "# TimeSeriesDataSet 생성\n",
    "# --------------------\n",
    "training = TimeSeriesDataSet(\n",
    "    data_full[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"requested_kwh\",\n",
    "    group_ids=group_cols,\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"station_location\", \"evse_name\", \"evse_type\", \"supports_discharge\"],\n",
    "    static_reals=[\"usage_departure_range\", \"post_charge_departure_range\", \"cluster\"] if \"usage_departure_range\" in data_full.columns else [],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\"],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        col for col in [\n",
    "            \"connection_start_time_ts\",\"last_charge_end_time_ts\", \"charging_end_time_ts\", \"connection_end_time_ts\", \"expected_departure_time_ts\",\n",
    "            \"expected_departure_time_missing\", \"idle_time_ts\", \"expected_usage_duration_ts\", \"expected_usage_duration_missing\",\n",
    "            \"expected_time_diff_ts\", \"expected_time_diff_missing\", \"actual_usage_duration_ts\", \"actual_charging_duration_ts\",\n",
    "            \"actual_charging_duration_missing\", \"start_delay_duration_ts\", \"start_delay_duration_missing\",\n",
    "            \"post_charge_departure_delay_ts\", \"post_charge_departure_delay_missing\",\n",
    "            \"usage_departure_time_diff_ts\", \"usage_departure_time_diff_missing\",\n",
    "            \"delivered_kwh\", \"requested_kwh\", \"kwh_request_diff\", \"kwh_per_usage_time\"\n",
    "        ] if col in data_full.columns\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(groups=group_cols, transformation=\"softplus\"),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fe52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_cols = [\"station_location\", \"evse_name\"]\n",
    "# max_continuous_lengths = []\n",
    "\n",
    "# for _, grp in data_full.groupby(group_cols):\n",
    "#     idx = grp[\"time_idx\"].sort_values()\n",
    "#     diff = idx.diff()\n",
    "#     # 연속 구간 마커\n",
    "#     breaks = diff[diff != 1].index\n",
    "#     # 구간별 길이 계산\n",
    "#     starts = [0] + list(breaks)\n",
    "#     ends = list(breaks) + [len(idx)]\n",
    "#     max_run = 0\n",
    "#     for s, e in zip(starts, ends):\n",
    "#         run_length = e - s\n",
    "#         if run_length > max_run:\n",
    "#             max_run = run_length\n",
    "#     max_continuous_lengths.append(max_run)\n",
    "\n",
    "# import numpy as np\n",
    "# print(\"그룹별 최대 연속 길이 예시:\", np.percentile(max_continuous_lengths, [10, 50, 90]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80659bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# TimeSeriesDataSet 생성\n",
    "# --------------------\n",
    "training = TimeSeriesDataSet(\n",
    "    data_full[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"requested_kwh\",\n",
    "    group_ids=group_cols,\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"station_location\", \"evse_name\", \"evse_type\", \"supports_discharge\"],\n",
    "    static_reals=[\"usage_departure_range\", \"post_charge_departure_range\", \"cluster\"] if \"usage_departure_range\" in data_full.columns else [],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\"],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        col for col in [\n",
    "            \"last_charge_end_time_ts\", \"charging_end_time_ts\", \"connection_end_time_ts\", \"expected_departure_time_ts\",\n",
    "            \"expected_departure_time_missing\", \"idle_time_ts\", \"expected_usage_duration_ts\", \"expected_usage_duration_missing\",\n",
    "            \"expected_time_diff_ts\", \"expected_time_diff_missing\", \"actual_usage_duration_ts\", \"actual_charging_duration_ts\",\n",
    "            \"actual_charging_duration_missing\", \"start_delay_duration_ts\", \"start_delay_duration_missing\",\n",
    "            \"post_charge_departure_delay_ts\", \"post_charge_departure_delay_missing\",\n",
    "            \"usage_departure_time_diff_ts\", \"usage_departure_time_diff_missing\",\n",
    "            \"delivered_kwh\", \"requested_kwh\", \"kwh_request_diff\", \"kwh_per_usage_time\"\n",
    "        ] if col in data_full.columns\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(groups=group_cols, transformation=\"softplus\"),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e65b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_encoder_time_idx = training_cutoff - max_encoder_length + 1  # encoder 구간 최소 시작 index\n",
    "future_data = data_full[data_full.time_idx >= min_encoder_time_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5836a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, future_data, predict=True, stop_randomization=True)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456d63cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station_location', 'evse_name', 'time_idx_raw',\n",
      "       'last_charge_end_time_ts', 'connection_start_time_ts',\n",
      "       'charging_start_time_ts', 'charging_start_time_missing',\n",
      "       'charging_end_time_ts', 'charging_end_time_missing',\n",
      "       'connection_end_time_ts', 'expected_departure_time_ts',\n",
      "       'expected_departure_time_missing', 'idle_time_ts',\n",
      "       'expected_usage_duration_ts', 'expected_usage_duration_missing',\n",
      "       'expected_time_diff_ts', 'expected_time_diff_missing',\n",
      "       'actual_usage_duration_ts', 'actual_charging_duration_ts',\n",
      "       'actual_charging_duration_missing', 'start_delay_duration_ts',\n",
      "       'start_delay_duration_missing', 'post_charge_departure_delay_ts',\n",
      "       'post_charge_departure_delay_missing', 'usage_departure_time_diff_ts',\n",
      "       'usage_departure_time_diff_missing', 'duration_per_kwh_ts',\n",
      "       'duration_per_kwh_missing', 'delivered_kwh', 'requested_kwh',\n",
      "       'kwh_request_diff', 'kwh_per_usage_time', 'kwh_per_usage_time_missing',\n",
      "       'evse_type', 'supports_discharge', 'scheduled_charge', 'weekday',\n",
      "       'usage_departure_range', 'post_charge_departure_range', 'cluster',\n",
      "       'time_idx', 'month', 'log_volume', 'avg_volume_by_evsename',\n",
      "       'usage_departure_time_diff_missing_filled'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_full.columns)  # 라벨 고유값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39d1003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:928\u001b[39m, in \u001b[36mTrainer._predict_impl\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[39m\n\u001b[32m    925\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    926\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    927\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:988\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    987\u001b[39m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:155\u001b[39m, in \u001b[36mStrategy.setup\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.precision_plugin.convert_module(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._setup_model(\u001b[38;5;28mself\u001b[39m.model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\strategies\\single_device.py:79\u001b[39m, in \u001b[36mSingleDeviceStrategy.model_to_device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mself.model must be set before self.model.to()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\fabric\\utilities\\device_dtype_mixin.py:55\u001b[39m, in \u001b[36m_DeviceDtypeModuleMixin.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m _update_properties(\u001b[38;5;28mself\u001b[39m, device=device, dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torchmetrics\\metric.py:907\u001b[39m, in \u001b[36mMetric._apply\u001b[39m\u001b[34m(self, fn, exclude_state)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# make sure to update the device attribute\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# if the dummy tensor moves device by fn function we should also update the attribute\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m _dummy_tensor = fn(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    908\u001b[39m \u001b[38;5;28mself\u001b[39m._device = _dummy_tensor.device\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43mbest_tft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\pytorch_forecasting\\models\\base\\_base_model.py:1723\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, data, mode, return_index, return_decoder_lengths, batch_size, num_workers, fast_dev_run, return_x, return_y, mode_kwargs, trainer_kwargs, write_interval, output_dir, **kwargs)\u001b[39m\n\u001b[32m   1721\u001b[39m logging.getLogger(\u001b[33m\"\u001b[39m\u001b[33mpytorch_lightning\u001b[39m\u001b[33m\"\u001b[39m).setLevel(logging.WARNING)\n\u001b[32m   1722\u001b[39m trainer = Trainer(fast_dev_run=fast_dev_run, **trainer_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1723\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1724\u001b[39m logging.getLogger(\u001b[33m\"\u001b[39m\u001b[33mlightning\u001b[39m\u001b[33m\"\u001b[39m).setLevel(log_level_lighting)\n\u001b[32m   1725\u001b[39m logging.getLogger(\u001b[33m\"\u001b[39m\u001b[33mpytorch_lightning\u001b[39m\u001b[33m\"\u001b[39m).setLevel(log_level_pytorch_lightning)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:887\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    886\u001b[39m \u001b[38;5;28mself\u001b[39m.predicting = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:69\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[32m     71\u001b[39m     trainer.state.stage = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1035\u001b[39m, in \u001b[36mTrainer._teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1033\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[33;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m     loop = \u001b[38;5;28mself\u001b[39m._active_loop\n\u001b[32m   1037\u001b[39m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:536\u001b[39m, in \u001b[36mStrategy.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    535\u001b[39m     log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: moving model to CPU\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.precision_plugin.teardown()\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\lightning\\fabric\\utilities\\device_dtype_mixin.py:82\u001b[39m, in \u001b[36m_DeviceDtypeModuleMixin.cpu\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001b[39;00m\n\u001b[32m     81\u001b[39m _update_properties(\u001b[38;5;28mself\u001b[39m, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1133\u001b[39m, in \u001b[36mModule.cpu\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) -> T:\n\u001b[32m   1125\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[32m   1126\u001b[39m \n\u001b[32m   1127\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1131\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   1132\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torchmetrics\\metric.py:891\u001b[39m, in \u001b[36mMetric._apply\u001b[39m\u001b[34m(self, fn, exclude_state)\u001b[39m\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     this._defaults[key] = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Sequence):\n\u001b[32m    893\u001b[39m     this._defaults[key] = [fn(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\.conda\\envs\\largeGarbage\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1133\u001b[39m, in \u001b[36mModule.cpu.<locals>.<lambda>\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) -> T:\n\u001b[32m   1125\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[32m   1126\u001b[39m \n\u001b[32m   1127\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1131\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   1132\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "predictions = best_tft.predict(val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = future_data.copy()\n",
    "import pandas as pd\n",
    "\n",
    "pred_array = predictions.detach().cpu().numpy()\n",
    "\n",
    "pred_df = original_data.iloc[:pred_array.shape[0]].copy()\n",
    "pred_df[\"predicted_requested_kwh\"] = pred_array[:, 0]\n",
    "\n",
    "pred_df.to_csv(\"predictions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "largeGarbage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
